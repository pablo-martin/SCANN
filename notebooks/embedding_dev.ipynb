{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmartEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modifying SmartEmbed\n",
    "- this library has some Python 2 stuff, had to quickly fix that\n",
    "- it has a java dependency. it's obviously deployable but i've never done that before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between c1 and c2: 0.8895723343637358\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from SmartEmbed.smartembed import SmartEmbed\n",
    "\n",
    "os.chdir(\"/Users/pablo/Documents/Coding/company_challenges/OpenZeppelin/SmartEmbed\")\n",
    "se = SmartEmbed()\n",
    "# read contract1 from file\n",
    "contract1 = open('todo/test.sol', 'r').read() \n",
    "# get vector representation for contract1\n",
    "vector1 = se.get_vector(contract1)\n",
    "# read contract2 from file\n",
    "contract2 = open('todo/KOTH.sol', 'r').read()\n",
    "# get vector representation for contract2\n",
    "vector2 = se.get_vector(contract2)\n",
    "# estimate similarity between contract1 and contract2 \n",
    "similarity = se.get_similarity(vector1, vector2)\n",
    "print(\"similarity between c1 and c2:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latency of calculating single embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vector1 = se.get_vector(contract1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process dataset\n",
    "- first let's scan and find out how many files there are\n",
    "- make decision as to how to store this data based on next step: FAISS\n",
    "- keep track of how many files this tool is not able to process also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "base_dir = \"/Users/pablo/Documents/Coding/company_challenges/OpenZeppelin/smart-contract-sanctuary-ethereum/contracts\"\n",
    "smart_embed_dir = \"/Users/pablo/Documents/Coding/company_challenges/OpenZeppelin/SmartEmbed\"\n",
    "ignore_dirs = (\".ipynb_checkpoints\")\n",
    "\n",
    "def contract_path_gen(base_dir: str):\n",
    "    for root,dirs,files in os.walk(base_dir, topdown=True):\n",
    "        for _file in files:\n",
    "            if _file.split(\".\")[-1] == \"sol\":\n",
    "                yield os.path.join(root, _file)\n",
    "    \n",
    "def read_contract(contract_path : str) -> str:\n",
    "    with open(contract_path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def get_embedding(contract_path: str):\n",
    "    try:\n",
    "        return {contract_path: se.get_vector(read_contract(contract_path))}\n",
    "    except: # be very broad here, we don't know what mistakes could happen \n",
    "        return dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of smart contracts: 1083325\n"
     ]
    }
   ],
   "source": [
    "n_contracts = sum([1 for _ in contract_path_gen(base_dir)])\n",
    "print(f\"total number of smart contracts: {n_contracts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "embeddings = dict()\n",
    "\n",
    "for ix, contract_path in enumerate(contract_path_gen(base_dir)):\n",
    "    contract = read_contract(contract_path)\n",
    "    embeddings[contract_path] = se.get_vector(contract)\n",
    "    if ix>100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there was a lot of warnings so i had to clear the outpu, but it took 28.5 seconds to process 100 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.76322916666666"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1083325 * 28.5) / (100 * 60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- that means 85 hours of procesing time. that's a problem, maybe we can parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import delayed, Parallel\n",
    "\n",
    "gen = contract_path_gen(base_dir)\n",
    "l = list()\n",
    "for ix, _cp in enumerate(gen):\n",
    "    if ix > 100:\n",
    "        break\n",
    "    l.append(_cp)\n",
    "    \n",
    "st = time.time()\n",
    "result = Parallel(n_jobs=-1)(delayed(get_embedding)(contract_path) for contract_path in l)\n",
    "elapsed = time.time() - st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 0:00:30.225761\n"
     ]
    }
   ],
   "source": [
    "print(f\"time elapsed: {timedelta(seconds=elapsed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- i don't know why parallelization is not speeding things up. it may have to do with running java command and java not handling concurrency well, i just don't know enough about java.\n",
    "- unfortuntately we have to keep moving, let's how the index part will work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify Annoy\n",
    "- i had considered using ElasticSearch, but I think deploying that will not be that easy\n",
    "- i was looking at Python only stuff and found FAISS, but you need cmake, and c++ BLAS libraries, and link everything, again worried about deployment due to time constraint\n",
    "- let's explore the Spotify annoy library, it looks better and simple pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "t = AnnoyIndex(150, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_item(1, vector1.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 1 µs, total: 23 µs\n",
      "Wall time: 25 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t.add_item(2, vector2.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.build(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_nns_by_item(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.save('test.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = AnnoyIndex(150, 'angular')\n",
    "u.load(\"test.ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.get_nns_by_item(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ok this will have to do and seems to have enough functionality for now. I'm going to work on a script that both saves the processed embeddings, and creates the index at the same time. \n",
    "- since parallelizing is not working, im going to do it serially which gives some advantages. i dont know if AnnoyIndex handles concurrency anyways, but i can save snapshots of the processed data which i can then work with separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def get_embedding2(contract_path: str) -> Dict:\n",
    "    try:\n",
    "        return {\n",
    "            \"contract_path\": contract_path,\n",
    "            \"embedding\": se.get_vector(read_contract(contract_path)).reshape(-1)}\n",
    "    except: # be very broad here, we don't know what mistakes could happen \n",
    "        return dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp = [get_embedding2(l[0]), get_embedding2(l[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract_id</th>\n",
       "      <th>contract_path</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/Users/pablo/Documents/Coding/company_challeng...</td>\n",
       "      <td>[404.5833587087691, -725.1700658425689, -302.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/Users/pablo/Documents/Coding/company_challeng...</td>\n",
       "      <td>[545.3918035291135, -195.70304829627275, -68.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contract_id                                      contract_path  \\\n",
       "0            0  /Users/pablo/Documents/Coding/company_challeng...   \n",
       "1            1  /Users/pablo/Documents/Coding/company_challeng...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [404.5833587087691, -725.1700658425689, -302.5...  \n",
       "1  [545.3918035291135, -195.70304829627275, -68.8...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index().rename(columns={\"index\":\"contract_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas is not that fast, but it's still an index and we're around 1M rows which is not that big\n",
    "- i will leave this as a parquet file \"database\", which is terrible, but since it's an MVP it will work, with the idea of moving to a full solution like ElasticSearch or DynamoDB in a following iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to-do\n",
    "- i need to figure out how to deploy a java environment\n",
    "- i need to commit all the changes i did to SmartEmbed library and create that fork. i need to figure out how i'm gonna install that in deployment, since it was in Python 2 and needed all those changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"debug.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 12:40:34,788 [INFO] Useful message\n"
     ]
    }
   ],
   "source": [
    "logging.info('Useful message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeppelin",
   "language": "python",
   "name": "zeppelin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
